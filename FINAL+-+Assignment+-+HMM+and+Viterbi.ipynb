{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using  vanila viterbi & modified Viterbi\n",
    "\n",
    "#### Note: Please run the whole note book "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_columns',5400)\n",
    "pd.set_option('display.max_rows',5400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('61', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('will', 'VERB'),\n",
       "  ('join', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('board', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('29', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  ('is', 'VERB'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Elsevier', 'NOUN'),\n",
       "  ('N.V.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('Dutch', 'NOUN'),\n",
       "  ('publishing', 'VERB'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NOUN'),\n",
       "  ('Agnew', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('55', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('former', 'ADJ'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Consolidated', 'NOUN'),\n",
       "  ('Gold', 'NOUN'),\n",
       "  ('Fields', 'NOUN'),\n",
       "  ('PLC', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('was', 'VERB'),\n",
       "  ('named', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('this', 'DET'),\n",
       "  ('British', 'ADJ'),\n",
       "  ('industrial', 'ADJ'),\n",
       "  ('conglomerate', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DET'),\n",
       "  ('form', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('once', 'ADV'),\n",
       "  ('used', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('make', 'VERB'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarette', 'NOUN'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('has', 'VERB'),\n",
       "  ('caused', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('high', 'ADJ'),\n",
       "  ('percentage', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('cancer', 'NOUN'),\n",
       "  ('deaths', 'NOUN'),\n",
       "  ('among', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('workers', 'NOUN'),\n",
       "  ('exposed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('more', 'ADV'),\n",
       "  ('than', 'ADP'),\n",
       "  ('30', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('reported', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('fiber', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('crocidolite', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('is', 'VERB'),\n",
       "  ('unusually', 'ADV'),\n",
       "  ('resilient', 'ADJ'),\n",
       "  ('once', 'ADP'),\n",
       "  ('it', 'PRON'),\n",
       "  ('enters', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('lungs', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('with', 'ADP'),\n",
       "  ('even', 'ADV'),\n",
       "  ('brief', 'ADJ'),\n",
       "  ('exposures', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('causing', 'VERB'),\n",
       "  ('symptoms', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('show', 'VERB'),\n",
       "  ('up', 'PRT'),\n",
       "  ('decades', 'NOUN'),\n",
       "  ('later', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('.', '.')],\n",
       " [('Lorillard', 'NOUN'),\n",
       "  ('Inc.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('unit', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('New', 'ADJ'),\n",
       "  ('York-based', 'ADJ'),\n",
       "  ('Loews', 'NOUN'),\n",
       "  ('Corp.', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('makes', 'VERB'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarettes', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('stopped', 'VERB'),\n",
       "  ('using', 'VERB'),\n",
       "  ('crocidolite', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('its', 'PRON'),\n",
       "  ('Micronite', 'NOUN'),\n",
       "  ('cigarette', 'NOUN'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('1956', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Although', 'ADP'),\n",
       "  ('preliminary', 'ADJ'),\n",
       "  ('findings', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  ('reported', 'VERB'),\n",
       "  ('*-2', 'X'),\n",
       "  ('more', 'ADV'),\n",
       "  ('than', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('year', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('latest', 'ADJ'),\n",
       "  ('results', 'NOUN'),\n",
       "  ('appear', 'VERB'),\n",
       "  ('in', 'ADP'),\n",
       "  ('today', 'NOUN'),\n",
       "  (\"'s\", 'PRT'),\n",
       "  ('New', 'NOUN'),\n",
       "  ('England', 'NOUN'),\n",
       "  ('Journal', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Medicine', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('a', 'DET'),\n",
       "  ('forum', 'NOUN'),\n",
       "  ('likely', 'ADJ'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('bring', 'VERB'),\n",
       "  ('new', 'ADJ'),\n",
       "  ('attention', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('the', 'DET'),\n",
       "  ('problem', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DET'),\n",
       "  ('Lorillard', 'NOUN'),\n",
       "  ('spokewoman', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  (',', '.'),\n",
       "  ('``', '.'),\n",
       "  ('This', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('an', 'DET'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('story', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('We', 'PRON'),\n",
       "  (\"'re\", 'VERB'),\n",
       "  ('talking', 'VERB'),\n",
       "  ('about', 'ADP'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  ('before', 'ADP'),\n",
       "  ('anyone', 'NOUN'),\n",
       "  ('heard', 'VERB'),\n",
       "  ('of', 'ADP'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('having', 'VERB'),\n",
       "  ('any', 'DET'),\n",
       "  ('questionable', 'ADJ'),\n",
       "  ('properties', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('There', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('no', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('our', 'PRON'),\n",
       "  ('products', 'NOUN'),\n",
       "  ('now', 'ADV'),\n",
       "  ('.', '.'),\n",
       "  (\"''\", '.')]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "nltk_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All words are tagged. \n",
    "#### words are theirs taggs are inside a tuple\n",
    "#### A sentence is represented as a list which congtains tuple of all words with taggs\n",
    "#### The whole Treebank is inside a list\n",
    "#### '.' can be considered as start. i.e. P(tag|start) = P(tag|.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data =  3718\n",
      "Length of test data =  196\n"
     ]
    }
   ],
   "source": [
    "#spliting into train_test\n",
    "\n",
    "random.seed(100)\n",
    "train_data,test_data=train_test_split(nltk_data,test_size=0.05,random_state=50)\n",
    "print('Length of train data = ',len(train_data))\n",
    "print('Length of test data = ',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95421\n",
      "5255\n"
     ]
    }
   ],
   "source": [
    "#creating a list of tagged word\n",
    "\n",
    "train_tagd=[tw for sent in train_data for tw in sent]\n",
    "test_tagd=[tw for sent in test_data for tw in sent]\n",
    "print(len(train_tagd))\n",
    "print(len(test_tagd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('problem', 'NOUN'),\n",
       " ('involves', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('motion', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('small', 'ADJ'),\n",
       " ('magnetic', 'ADJ'),\n",
       " ('fields', 'NOUN'),\n",
       " ('within', 'ADP'),\n",
       " ('superconductor', 'NOUN'),\n",
       " ('crystals', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('*', 'X'),\n",
       " ('limiting', 'VERB')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagd[0:15] #(word,POS tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique token =  12059\n",
      "number of unique POS tags =  12\n"
     ]
    }
   ],
   "source": [
    "# creating a vocabulary by extracting unique tokens(words,symbols,numbers) and unique POS tags\n",
    "\n",
    "#tokens\n",
    "V=set([i[0] for i in train_tagd])\n",
    "\n",
    "#POS tags\n",
    "T = set([i[1] for i in train_tagd])\n",
    "\n",
    "print('number of unique token = ',len(V))\n",
    "print('number of unique POS tags = ', len(T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique pos tags are\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating parameters for HMM model\n",
    "\n",
    "# Emission Probability\n",
    "\n",
    "def w_g_t ( word,tag, train_d=train_tagd):\n",
    "    onlyt=[wt for wt in train_d if wt[1]==tag ]\n",
    "    w=[w for w in onlyt if w[0]==word]\n",
    "    emission = len(w)/len(onlyt)\n",
    "    \n",
    "    return emission\n",
    "\n",
    "#Transition probability\n",
    "\n",
    "def t2_g_t1(t2,t1,train_d=train_tagd):\n",
    "    tags=[i[1] for i in train_d]\n",
    "    t1_c=[t for t in tags if t == t1]\n",
    "    t2_t1_c=0\n",
    "    for i in range(len(tags)-1):\n",
    "        if tags[i]==t1 and tags[i+1] ==t2 :\n",
    "            t2_t1_c+=1\n",
    "            \n",
    "    transition=t2_t1_c/len(t1_c)\n",
    "            \n",
    "    return (transition)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a matrix to represent the relationship P(t2|t1) TxT MATRIX\n",
    "\n",
    "tags_matrix=np.zeros((len(T),len(T)),dtype='float32')\n",
    "tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.68022253e-02, 7.02054799e-02, 1.04880139e-01, 8.34760256e-03,\n",
       "        1.39126717e-03, 6.15368150e-02, 3.21810782e-01, 3.94905806e-02,\n",
       "        1.41267125e-02, 8.56164377e-04, 3.49957198e-02, 3.25556517e-01],\n",
       "       [2.29973178e-02, 8.04906059e-03, 7.28248358e-02, 4.86776531e-01,\n",
       "        1.22652361e-02, 6.89919526e-03, 2.08892301e-01, 4.10118811e-02,\n",
       "        3.37293968e-02, 4.98275179e-03, 9.19892713e-02, 9.58221499e-03],\n",
       "       [7.79306889e-02, 6.63239916e-04, 6.58265650e-02, 1.19383186e-02,\n",
       "        1.02802189e-02, 2.02288181e-02, 6.99220717e-01, 6.66556135e-02,\n",
       "        4.97429958e-03, 1.65809989e-02, 2.07262486e-02, 4.97429958e-03],\n",
       "       [9.15531367e-02, 3.56558971e-02, 6.53950945e-02, 1.69015184e-01,\n",
       "        3.11405212e-02, 2.30439864e-02, 1.10782407e-01, 3.47995311e-02,\n",
       "        8.10432062e-02, 5.29388851e-03, 2.17983648e-01, 1.34293497e-01],\n",
       "       [2.00856104e-02, 1.74514316e-02, 8.29766244e-02, 4.03029293e-01,\n",
       "        1.97563390e-03, 5.82811981e-02, 2.46954232e-01, 4.34639454e-02,\n",
       "        9.54889692e-03, 1.64636155e-03, 1.41587090e-02, 1.00428052e-01],\n",
       "       [3.48317958e-02, 1.48853823e-03, 3.24501358e-02, 1.72670446e-02,\n",
       "        2.79845186e-02, 1.85769573e-01, 3.51295024e-01, 1.18189938e-01,\n",
       "        2.67936895e-03, 1.39922593e-02, 2.11074725e-01, 2.97707645e-03],\n",
       "       [1.76853344e-01, 4.64249169e-03, 1.20266117e-02, 1.46329880e-01,\n",
       "        4.35370654e-02, 9.46775824e-03, 2.64037132e-01, 2.41373003e-01,\n",
       "        1.73270945e-02, 4.24769707e-02, 2.88784914e-02, 1.30501539e-02],\n",
       "       [9.08357278e-02, 6.54591098e-02, 4.51040156e-02, 8.85939747e-02,\n",
       "        2.42109038e-03, 8.08823556e-02, 2.22919658e-01, 9.32568163e-02,\n",
       "        5.21879494e-02, 5.76578192e-02, 2.72596851e-02, 1.73332140e-01],\n",
       "       [1.19586945e-01, 1.46568958e-02, 1.28914058e-01, 3.45769495e-01,\n",
       "        1.46568958e-02, 3.16455700e-02, 3.16455700e-02, 1.34910062e-01,\n",
       "        7.96135888e-02, 6.99533662e-03, 2.29846761e-02, 6.86209202e-02],\n",
       "       [5.32959327e-02, 6.17110804e-02, 1.17812060e-01, 1.54745206e-01,\n",
       "        4.67508193e-03, 4.16082293e-02, 3.51566166e-01, 3.45956050e-02,\n",
       "        5.28284237e-02, 4.67508187e-04, 7.94763863e-03, 1.18747078e-01],\n",
       "       [1.44065097e-01, 5.56796417e-02, 1.57945119e-02, 2.03892782e-01,\n",
       "        1.84428841e-01, 2.87172943e-03, 6.26994222e-02, 1.64326742e-01,\n",
       "        2.55264845e-02, 1.06892148e-02, 7.51435831e-02, 5.48819415e-02],\n",
       "       [9.17985290e-03, 3.62362596e-03, 2.04493299e-01, 4.03430350e-02,\n",
       "        2.41575064e-04, 2.22249068e-02, 6.38362110e-01, 1.76349804e-02,\n",
       "        1.26826912e-02, 4.83150128e-04, 4.50537503e-02, 5.67701412e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,t1 in enumerate(list(T)):\n",
    "    for j,t2 in enumerate(list(T)):\n",
    "        tags_matrix[i,j]=t2_g_t1(t2,t1)\n",
    "tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADP</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PRT</th>\n",
       "      <th>NUM</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>.</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>X</th>\n",
       "      <th>DET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.016802</td>\n",
       "      <td>0.070205</td>\n",
       "      <td>0.104880</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.061537</td>\n",
       "      <td>0.321811</td>\n",
       "      <td>0.039491</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.034996</td>\n",
       "      <td>0.325557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.022997</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.072825</td>\n",
       "      <td>0.486777</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>0.208892</td>\n",
       "      <td>0.041012</td>\n",
       "      <td>0.033729</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.091989</td>\n",
       "      <td>0.009582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.077931</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.065827</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.020229</td>\n",
       "      <td>0.699221</td>\n",
       "      <td>0.066656</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>0.016581</td>\n",
       "      <td>0.020726</td>\n",
       "      <td>0.004974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.091553</td>\n",
       "      <td>0.035656</td>\n",
       "      <td>0.065395</td>\n",
       "      <td>0.169015</td>\n",
       "      <td>0.031141</td>\n",
       "      <td>0.023044</td>\n",
       "      <td>0.110782</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.081043</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.217984</td>\n",
       "      <td>0.134293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.020086</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>0.082977</td>\n",
       "      <td>0.403029</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.058281</td>\n",
       "      <td>0.246954</td>\n",
       "      <td>0.043464</td>\n",
       "      <td>0.009549</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.100428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.034832</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.027985</td>\n",
       "      <td>0.185770</td>\n",
       "      <td>0.351295</td>\n",
       "      <td>0.118190</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>0.211075</td>\n",
       "      <td>0.002977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.176853</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.146330</td>\n",
       "      <td>0.043537</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.264037</td>\n",
       "      <td>0.241373</td>\n",
       "      <td>0.017327</td>\n",
       "      <td>0.042477</td>\n",
       "      <td>0.028878</td>\n",
       "      <td>0.013050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.090836</td>\n",
       "      <td>0.065459</td>\n",
       "      <td>0.045104</td>\n",
       "      <td>0.088594</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.080882</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.093257</td>\n",
       "      <td>0.052188</td>\n",
       "      <td>0.057658</td>\n",
       "      <td>0.027260</td>\n",
       "      <td>0.173332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.119587</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.128914</td>\n",
       "      <td>0.345769</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.031646</td>\n",
       "      <td>0.031646</td>\n",
       "      <td>0.134910</td>\n",
       "      <td>0.079614</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>0.022985</td>\n",
       "      <td>0.068621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.053296</td>\n",
       "      <td>0.061711</td>\n",
       "      <td>0.117812</td>\n",
       "      <td>0.154745</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.041608</td>\n",
       "      <td>0.351566</td>\n",
       "      <td>0.034596</td>\n",
       "      <td>0.052828</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.007948</td>\n",
       "      <td>0.118747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.144065</td>\n",
       "      <td>0.055680</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>0.203893</td>\n",
       "      <td>0.184429</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.062699</td>\n",
       "      <td>0.164327</td>\n",
       "      <td>0.025526</td>\n",
       "      <td>0.010689</td>\n",
       "      <td>0.075144</td>\n",
       "      <td>0.054882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.204493</td>\n",
       "      <td>0.040343</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>0.638362</td>\n",
       "      <td>0.017635</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.045054</td>\n",
       "      <td>0.005677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADP      PRON       ADJ      VERB       PRT       NUM      NOUN  \\\n",
       "ADP   0.016802  0.070205  0.104880  0.008348  0.001391  0.061537  0.321811   \n",
       "PRON  0.022997  0.008049  0.072825  0.486777  0.012265  0.006899  0.208892   \n",
       "ADJ   0.077931  0.000663  0.065827  0.011938  0.010280  0.020229  0.699221   \n",
       "VERB  0.091553  0.035656  0.065395  0.169015  0.031141  0.023044  0.110782   \n",
       "PRT   0.020086  0.017451  0.082977  0.403029  0.001976  0.058281  0.246954   \n",
       "NUM   0.034832  0.001489  0.032450  0.017267  0.027985  0.185770  0.351295   \n",
       "NOUN  0.176853  0.004642  0.012027  0.146330  0.043537  0.009468  0.264037   \n",
       ".     0.090836  0.065459  0.045104  0.088594  0.002421  0.080882  0.222920   \n",
       "ADV   0.119587  0.014657  0.128914  0.345769  0.014657  0.031646  0.031646   \n",
       "CONJ  0.053296  0.061711  0.117812  0.154745  0.004675  0.041608  0.351566   \n",
       "X     0.144065  0.055680  0.015795  0.203893  0.184429  0.002872  0.062699   \n",
       "DET   0.009180  0.003624  0.204493  0.040343  0.000242  0.022225  0.638362   \n",
       "\n",
       "             .       ADV      CONJ         X       DET  \n",
       "ADP   0.039491  0.014127  0.000856  0.034996  0.325557  \n",
       "PRON  0.041012  0.033729  0.004983  0.091989  0.009582  \n",
       "ADJ   0.066656  0.004974  0.016581  0.020726  0.004974  \n",
       "VERB  0.034800  0.081043  0.005294  0.217984  0.134293  \n",
       "PRT   0.043464  0.009549  0.001646  0.014159  0.100428  \n",
       "NUM   0.118190  0.002679  0.013992  0.211075  0.002977  \n",
       "NOUN  0.241373  0.017327  0.042477  0.028878  0.013050  \n",
       ".     0.093257  0.052188  0.057658  0.027260  0.173332  \n",
       "ADV   0.134910  0.079614  0.006995  0.022985  0.068621  \n",
       "CONJ  0.034596  0.052828  0.000468  0.007948  0.118747  \n",
       "X     0.164327  0.025526  0.010689  0.075144  0.054882  \n",
       "DET   0.017635  0.012683  0.000483  0.045054  0.005677  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a DataFrame\n",
    "tags_df= pd.DataFrame(tags_matrix,columns=list(T),index=list(T))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING THE HMM-VITERBI ALGORITHM ( VANILA VITERBI FORM)\n",
    "\n",
    "def h_viterbi(words,train_bag=train_tagd):\n",
    "    pos=[]\n",
    "    T=list(set([i[1] for i in train_bag]))\n",
    "    \n",
    "    for index, word in enumerate(words):\n",
    "        state_p=[]\n",
    "        for tag in T:\n",
    "            if index ==0:\n",
    "                transition_p=tags_df.loc['.',tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[pos[-1],tag]\n",
    "                \n",
    "            #emission probability\n",
    "            emission_p = w_g_t(words[index],tag)\n",
    "            state=transition_p * emission_p\n",
    "            state_p.append(state)\n",
    "            \n",
    "        max_p=max(state_p) #evaluating maximum likelyhood\n",
    "        \n",
    "        w_pos=T[state_p.index(max_p)]\n",
    "        pos.append(w_pos)\n",
    "    \n",
    "    return list(zip(words,pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Editorials',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Greenville',\n",
       " 'newspaper',\n",
       " 'allowed',\n",
       " 'that',\n",
       " 'Mrs.',\n",
       " 'Yeargin',\n",
       " 'was']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating tokens \n",
    "\n",
    "test_words=[i[0] for i in test_tagd]\n",
    "test_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Editorials', 'ADP'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('Greenville', 'NOUN'),\n",
       " ('newspaper', 'NOUN'),\n",
       " ('allowed', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('Mrs.', 'NOUN'),\n",
       " ('Yeargin', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('wrong', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('but', 'CONJ'),\n",
       " ('also', 'ADV'),\n",
       " ('said', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('the', 'DET'),\n",
       " ('case', 'NOUN'),\n",
       " ('showed', 'VERB'),\n",
       " ('how', 'ADV'),\n",
       " ('testing', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('being', 'VERB'),\n",
       " ('overused', 'ADP'),\n",
       " ('*-2', 'X'),\n",
       " ('*T*-1', 'X'),\n",
       " ('.', '.'),\n",
       " ('--', '.'),\n",
       " ('And', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('USIA', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('all', 'DET'),\n",
       " ('of', 'ADP'),\n",
       " ('us', 'PRON'),\n",
       " ('could', 'VERB'),\n",
       " ('take', 'VERB'),\n",
       " ('extensive', 'ADJ'),\n",
       " ('notes', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Meanwhile', 'ADV'),\n",
       " (',', '.'),\n",
       " ('many', 'ADJ'),\n",
       " ('market', 'NOUN'),\n",
       " ('watchers', 'NOUN'),\n",
       " ('say', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('recent', 'ADJ'),\n",
       " ('dividend', 'NOUN'),\n",
       " ('trends', 'NOUN'),\n",
       " ('raise', 'VERB'),\n",
       " ('another', 'DET'),\n",
       " ('warning', 'NOUN'),\n",
       " ('flag', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('While', 'ADP'),\n",
       " ('dividends', 'NOUN'),\n",
       " ('have', 'VERB'),\n",
       " ('risen', 'VERB'),\n",
       " ('smartly', 'ADP'),\n",
       " (',', '.'),\n",
       " ('their', 'PRON'),\n",
       " ('expansion', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " (\"n't\", 'ADV'),\n",
       " ('kept', 'VERB'),\n",
       " ('pace', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('even', 'ADV'),\n",
       " ('stronger', 'ADJ'),\n",
       " ('advances', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('stock', 'NOUN'),\n",
       " ('prices', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('A', 'DET'),\n",
       " ('large', 'ADJ'),\n",
       " ('investor', 'NOUN'),\n",
       " ('will', 'VERB'),\n",
       " ('likely', 'ADJ'),\n",
       " ('cause', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('futures', 'NOUN'),\n",
       " ('market', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('decline', 'VERB'),\n",
       " ('when', 'ADV'),\n",
       " ('he', 'PRON'),\n",
       " ('sells', 'VERB'),\n",
       " ('his', 'PRON'),\n",
       " ('futures', 'NOUN'),\n",
       " ('*T*-1', 'X'),\n",
       " ('.', '.'),\n",
       " ('No', 'DET'),\n",
       " ('one', 'NUM'),\n",
       " ('is', 'VERB'),\n",
       " ('more', 'ADV'),\n",
       " ('unhappy', 'ADJ'),\n",
       " ('with', 'ADP'),\n",
       " ('program', 'NOUN'),\n",
       " ('trading', 'NOUN'),\n",
       " ('than', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('nation', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('stockbrokers', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('``', '.'),\n",
       " ('You', 'PRON'),\n",
       " ('have', 'VERB'),\n",
       " ('...', '.'),\n",
       " ('raised', 'VERB'),\n",
       " ('important', 'ADJ'),\n",
       " ('questions', 'NOUN'),\n",
       " ('which', 'DET'),\n",
       " ('*T*-26', 'X'),\n",
       " ('ought', 'VERB'),\n",
       " ('*-2', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('answered', 'VERB'),\n",
       " ('*-3', 'X'),\n",
       " (':', '.'),\n",
       " ('What', 'PRON'),\n",
       " ('does', 'VERB'),\n",
       " ('USIA', 'NOUN'),\n",
       " ('say', 'VERB'),\n",
       " ('*T*-27', 'X'),\n",
       " ('about', 'ADP'),\n",
       " ('America', 'NOUN'),\n",
       " ('abroad', 'ADV'),\n",
       " (';', '.'),\n",
       " ('how', 'ADV'),\n",
       " ('do', 'VERB'),\n",
       " ('we', 'PRON'),\n",
       " ('say', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('*T*-4', 'X'),\n",
       " (';', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('how', 'ADV'),\n",
       " ('can', 'VERB'),\n",
       " ('American', 'ADJ'),\n",
       " ('taxpayers', 'NOUN'),\n",
       " ('get', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('answers', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('these', 'DET'),\n",
       " ('questions', 'NOUN'),\n",
       " ('*T*-5', 'X'),\n",
       " ('?', '.'),\n",
       " (\"''\", '.'),\n",
       " ('a', 'DET'),\n",
       " ('man', 'NOUN'),\n",
       " ('wrote', 'VERB'),\n",
       " ('me', 'PRON'),\n",
       " ('*T*-1', 'X'),\n",
       " ('a', 'DET'),\n",
       " ('couple', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('years', 'NOUN'),\n",
       " ('ago', 'ADP'),\n",
       " ('.', '.'),\n",
       " ('Meanwhile', 'ADV'),\n",
       " (',', '.'),\n",
       " ('Treasury', 'NOUN'),\n",
       " ('bonds', 'NOUN'),\n",
       " ('ended', 'VERB'),\n",
       " ('modestly', 'ADV'),\n",
       " ('higher', 'ADJ'),\n",
       " ('in', 'ADP'),\n",
       " ('quiet', 'ADJ'),\n",
       " ('trading', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRON'),\n",
       " ('employs', 'VERB'),\n",
       " ('2,700', 'ADP'),\n",
       " ('people', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('has', 'VERB'),\n",
       " ('annual', 'ADJ'),\n",
       " ('revenue', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('370', 'ADP'),\n",
       " ('million', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('.', '.'),\n",
       " ('But', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('New', 'NOUN'),\n",
       " ('York', 'NOUN'),\n",
       " ('Stock', 'NOUN'),\n",
       " ('Exchange', 'NOUN'),\n",
       " ('chairman', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('he', 'PRON'),\n",
       " ('does', 'VERB'),\n",
       " (\"n't\", 'ADV'),\n",
       " ('support', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('reinstating', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('``', '.'),\n",
       " ('collar', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('on', 'ADP'),\n",
       " ('program', 'NOUN'),\n",
       " ('trading', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('*-1', 'X'),\n",
       " ('arguing', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('firms', 'NOUN'),\n",
       " ('could', 'VERB'),\n",
       " ('get', 'VERB'),\n",
       " ('around', 'ADP'),\n",
       " ('such', 'ADJ'),\n",
       " ('a', 'DET'),\n",
       " ('limit', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Nekoosa', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('given', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('offer', 'NOUN'),\n",
       " ('a', 'DET'),\n",
       " ('public', 'ADJ'),\n",
       " ('cold', 'NOUN'),\n",
       " ('shoulder', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('a', 'DET'),\n",
       " ('reaction', 'NOUN'),\n",
       " ('0', 'X'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Hahn', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " (\"n't\", 'ADV'),\n",
       " ('faced', 'VERB'),\n",
       " ('*T*-2', 'X'),\n",
       " ('in', 'ADP'),\n",
       " ('his', 'PRON'),\n",
       " ('18', 'NUM'),\n",
       " ('earlier', 'ADJ'),\n",
       " ('acquisitions', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('all', 'DET'),\n",
       " ('of', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('*T*-3', 'X'),\n",
       " ('were', 'VERB'),\n",
       " ('negotiated', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('behind', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('scenes', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('In', 'ADP'),\n",
       " ('national', 'ADJ'),\n",
       " ('over-the-counter', 'ADJ'),\n",
       " ('trading', 'NOUN'),\n",
       " ('yesterday', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('POP', 'NOUN'),\n",
       " ('plunged', 'VERB'),\n",
       " ('$', '.'),\n",
       " ('4', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('$', '.'),\n",
       " ('14.75', 'ADP'),\n",
       " ('*U*', 'X'),\n",
       " ('.', '.'),\n",
       " ('Campbell', 'NOUN'),\n",
       " ('Soup', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('for', 'ADP'),\n",
       " ('one', 'NUM'),\n",
       " (',', '.'),\n",
       " ('is', 'VERB'),\n",
       " ('furious', 'ADP'),\n",
       " ('0', 'X'),\n",
       " ('its', 'PRON'),\n",
       " ('Souper', 'NOUN'),\n",
       " ('Combo', 'NOUN'),\n",
       " ('microwave', 'ADP'),\n",
       " ('product', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('chastised', 'VERB'),\n",
       " ('*-79', 'X'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('premiere', 'NOUN'),\n",
       " ('``', '.'),\n",
       " ('In', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('Dumpster', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('column', 'ADP'),\n",
       " ('.', '.'),\n",
       " ('Junk', 'ADP'),\n",
       " ('bonds', 'NOUN'),\n",
       " ('trailed', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('group', 'NOUN'),\n",
       " ('again', 'ADV'),\n",
       " ('.', '.'),\n",
       " ('For', 'ADP'),\n",
       " ('example', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('there', 'DET'),\n",
       " ('are', 'VERB'),\n",
       " ('options', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('S&P', 'NOUN'),\n",
       " ('500', 'NUM'),\n",
       " ('futures', 'NOUN'),\n",
       " ('contract', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('S&P', 'NOUN'),\n",
       " ('100', 'NUM'),\n",
       " ('index', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Giant', 'NOUN'),\n",
       " ('Group', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('led', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('by', 'ADP'),\n",
       " ('three', 'NUM'),\n",
       " ('Rally', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('directors', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Burt', 'NOUN'),\n",
       " ('Sugarman', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('James', 'NOUN'),\n",
       " ('M.', 'NOUN'),\n",
       " ('Trotter', 'NOUN'),\n",
       " ('III', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('William', 'NOUN'),\n",
       " ('E.', 'NOUN'),\n",
       " ('Trotter', 'NOUN'),\n",
       " ('II', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('who', 'PRON'),\n",
       " ('earlier', 'ADJ'),\n",
       " ('this', 'DET'),\n",
       " ('month', 'NOUN'),\n",
       " ('*T*-2', 'X'),\n",
       " ('indicated', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('they', 'PRON'),\n",
       " ('had', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('42.5', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('stake', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('Rally', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('and', 'CONJ'),\n",
       " ('planned', 'VERB'),\n",
       " ('*-3', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('seek', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('majority', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('seats', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('Rally', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('nine-member', 'ADJ'),\n",
       " ('board', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Dr.', 'NOUN'),\n",
       " ('Talcott', 'NOUN'),\n",
       " ('led', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('team', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('researchers', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('National', 'NOUN'),\n",
       " ('Cancer', 'NOUN'),\n",
       " ('Institute', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('medical', 'ADJ'),\n",
       " ('schools', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Harvard', 'NOUN'),\n",
       " ('University', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Boston', 'NOUN'),\n",
       " ('University', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('-LRB-', '.'),\n",
       " ('During', 'ADP'),\n",
       " ('its', 'PRON'),\n",
       " ('centennial', 'ADP'),\n",
       " ('year', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('The', 'DET'),\n",
       " ('Wall', 'NOUN'),\n",
       " ('Street', 'NOUN'),\n",
       " ('Journal', 'NOUN'),\n",
       " ('will', 'VERB'),\n",
       " ('report', 'NOUN'),\n",
       " ('events', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('past', 'ADJ'),\n",
       " ('century', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('*T*-30', 'X'),\n",
       " ('stand', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('milestones', 'ADP'),\n",
       " ('of', 'ADP'),\n",
       " ('American', 'NOUN'),\n",
       " ('business', 'NOUN'),\n",
       " ('history', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('-RRB-', '.'),\n",
       " ('``', '.'),\n",
       " ('There', 'DET'),\n",
       " ('may', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('viewpoint', 'NOUN'),\n",
       " ('cast', 'VERB'),\n",
       " ('*-2', 'X'),\n",
       " ('on', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('funds', 'NOUN'),\n",
       " ('listed', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('here', 'ADV'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Porter', 'NOUN'),\n",
       " ('says', 'VERB'),\n",
       " ('*T*-1', 'X'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('Midwest', 'NOUN'),\n",
       " ('Financial', 'NOUN'),\n",
       " ('subsidiary', 'NOUN'),\n",
       " ('banks', 'NOUN'),\n",
       " ('will', 'VERB'),\n",
       " ('continue', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('operate', 'VERB'),\n",
       " ('under', 'ADP'),\n",
       " ('their', 'PRON'),\n",
       " ('current', 'ADJ'),\n",
       " ('names', 'NOUN'),\n",
       " ('until', 'ADP'),\n",
       " ('early', 'ADJ'),\n",
       " ('1990', 'NUM'),\n",
       " (',', '.'),\n",
       " ('when', 'ADV'),\n",
       " ('each', 'DET'),\n",
       " ('will', 'VERB'),\n",
       " ('adopt', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('First', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('America', 'NOUN'),\n",
       " ('name', 'NOUN'),\n",
       " ('*T*-2', 'X'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('company', 'NOUN'),\n",
       " ('earlier', 'ADV'),\n",
       " ('this', 'DET'),\n",
       " ('year', 'NOUN'),\n",
       " ('adopted', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('shareholder-rights', 'ADP'),\n",
       " ('plan', 'NOUN'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('ward', 'VERB'),\n",
       " ('off', 'PRT'),\n",
       " ('unwanted', 'ADP'),\n",
       " ('suitors', 'ADP'),\n",
       " ('.', '.'),\n",
       " ('Reliance', 'NOUN'),\n",
       " ('confirmed', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('filing', 'NOUN'),\n",
       " ('but', 'CONJ'),\n",
       " ('would', 'VERB'),\n",
       " (\"n't\", 'ADV'),\n",
       " ('elaborate', 'VERB'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRON'),\n",
       " ('eventually', 'ADV'),\n",
       " ('secured', 'VERB'),\n",
       " ('Ministry', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Health', 'NOUN'),\n",
       " ('import', 'NOUN'),\n",
       " ('approval', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('two', 'NUM'),\n",
       " ('Candela', 'NOUN'),\n",
       " ('laser', 'ADP'),\n",
       " ('products', 'NOUN'),\n",
       " ('--', '.'),\n",
       " ('one', 'NUM'),\n",
       " ('that', 'ADP'),\n",
       " ('*T*-189', 'ADP'),\n",
       " ('breaks', 'VERB'),\n",
       " ('up', 'ADV'),\n",
       " ('kidney', 'ADP'),\n",
       " ('stones', 'ADP'),\n",
       " ('and', 'CONJ'),\n",
       " ('another', 'DET'),\n",
       " ('that', 'ADP'),\n",
       " ('*T*-190', 'ADP'),\n",
       " ('treats', 'ADP'),\n",
       " ('skin', 'NOUN'),\n",
       " ('lesions', 'ADP'),\n",
       " ('.', '.'),\n",
       " ('Labor', 'NOUN'),\n",
       " ('Secretary', 'NOUN'),\n",
       " ('Elizabeth', 'NOUN'),\n",
       " ('Dole', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " (',', '.'),\n",
       " ('``', '.'),\n",
       " ('The', 'DET'),\n",
       " ('magnitude', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('these', 'DET'),\n",
       " ('penalties', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('citations', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('matched', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('only', 'ADV'),\n",
       " ('by', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('magnitude', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('hazards', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('workers', 'NOUN'),\n",
       " ('which', 'DET'),\n",
       " ('*T*-14', 'X'),\n",
       " ('resulted', 'ADP'),\n",
       " ('from', 'ADP'),\n",
       " ('corporate', 'ADJ'),\n",
       " ('indifference', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('worker', 'NOUN'),\n",
       " ('safety', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('health', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('severe', 'ADJ'),\n",
       " ('cutbacks', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('maintenance', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('repair', 'NOUN'),\n",
       " ('programs', 'NOUN'),\n",
       " ('needed', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('remove', 'VERB'),\n",
       " ('those', 'DET'),\n",
       " ('hazards', 'NOUN'),\n",
       " ('.', '.'),\n",
       " (\"''\", '.'),\n",
       " ('The', 'DET'),\n",
       " ('7', 'NUM'),\n",
       " ('3\\\\/8', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('term', 'NOUN'),\n",
       " ('bonds', 'NOUN'),\n",
       " ('due', 'ADJ'),\n",
       " ('2009', 'NUM'),\n",
       " ('are', 'VERB'),\n",
       " ('priced', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('at', 'ADP'),\n",
       " ('99', 'NUM'),\n",
       " ('1\\\\/2', 'NUM'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('yield', 'VERB'),\n",
       " ('7.422', 'ADP'),\n",
       " ('%', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('7', 'NUM'),\n",
       " ('3\\\\/8', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('term', 'NOUN'),\n",
       " ('bonds', 'NOUN'),\n",
       " ('due', 'ADJ'),\n",
       " ('2019', 'NUM'),\n",
       " ('are', 'VERB'),\n",
       " ('priced', 'VERB'),\n",
       " ('*-2', 'X'),\n",
       " ('at', 'ADP'),\n",
       " ('99', 'NUM'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('yield', 'VERB'),\n",
       " ('7.458', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('In', 'ADP'),\n",
       " ('Chile', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('workers', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('two', 'NUM'),\n",
       " ('copper', 'NOUN'),\n",
       " ('mines', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Los', 'NOUN'),\n",
       " ('Bronces', 'ADP'),\n",
       " ('and', 'CONJ'),\n",
       " ('El', 'NOUN'),\n",
       " ('Soldado', 'ADP'),\n",
       " (',', '.'),\n",
       " ('which', 'DET'),\n",
       " ('*T*-1', 'X'),\n",
       " ('belong', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('the', 'DET'),\n",
       " ('Exxon-owned', 'ADP'),\n",
       " ('Minera', 'ADP'),\n",
       " ('Disputada', 'ADP'),\n",
       " (',', '.'),\n",
       " ('yesterday', 'NOUN'),\n",
       " ('voted', 'VERB'),\n",
       " ('*-2', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('begin', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('full', 'ADJ'),\n",
       " ('strike', 'NOUN'),\n",
       " ('tomorrow', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('an', 'DET'),\n",
       " ('analyst', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('*T*-3', 'X'),\n",
       " ('.', '.'),\n",
       " ('Previously', 'ADV'),\n",
       " (',', '.'),\n",
       " ('it', 'PRON'),\n",
       " ('offered', 'VERB'),\n",
       " ('$', '.'),\n",
       " ('13.65', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('a', 'DET'),\n",
       " ('share', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('cash', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('or', 'CONJ'),\n",
       " ('$', '.'),\n",
       " ('29', 'NUM'),\n",
       " ('million', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRON'),\n",
       " ('and', 'CONJ'),\n",
       " ('others', 'NOUN'),\n",
       " ('prefer', 'ADP'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('install', 'VERB'),\n",
       " ('railings', 'NOUN'),\n",
       " ('such', 'ADJ'),\n",
       " ('as', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('``', '.'),\n",
       " ('type', 'NOUN'),\n",
       " ('F', 'NOUN'),\n",
       " ('safety', 'NOUN'),\n",
       " ('shape', 'NOUN'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('a', 'DET'),\n",
       " ('four-foot-high', 'ADP'),\n",
       " ('concrete', 'ADJ'),\n",
       " ('slab', 'ADP'),\n",
       " ('with', 'ADP'),\n",
       " ('no', 'DET'),\n",
       " ('openings', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('A', 'DET'),\n",
       " ('few', 'ADJ'),\n",
       " ('fast-food', 'NOUN'),\n",
       " ('outlets', 'NOUN'),\n",
       " ('are', 'VERB'),\n",
       " ('giving', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('a', 'DET'),\n",
       " ('try', 'VERB'),\n",
       " ('.', '.'),\n",
       " ('Ford', 'NOUN'),\n",
       " ('Chairman', 'NOUN'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('E.', 'NOUN'),\n",
       " ('Petersen', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('yesterday', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Veraldi', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('helped', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('change', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('world', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('perception', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('American-made', 'ADP'),\n",
       " ('cars', 'NOUN'),\n",
       " ('.', '.'),\n",
       " (\"''\", '.'),\n",
       " ('McGraw-Hill', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('outraged', 'ADP'),\n",
       " ('.', '.'),\n",
       " ('Your', 'PRON'),\n",
       " ('research', 'NOUN'),\n",
       " ('stopped', 'VERB'),\n",
       " ('when', 'ADV'),\n",
       " ('a', 'DET'),\n",
       " ('convenient', 'ADJ'),\n",
       " ('assertion', 'NOUN'),\n",
       " ('could', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('made', 'VERB'),\n",
       " ('*-22', 'X'),\n",
       " ('*T*-1', 'X'),\n",
       " ('.', '.'),\n",
       " ('But', 'CONJ'),\n",
       " ('New', 'NOUN'),\n",
       " ('York', 'NOUN'),\n",
       " ('state', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('which', 'DET'),\n",
       " ('*T*-13', 'X'),\n",
       " ('is', 'VERB'),\n",
       " ('seeking', 'VERB'),\n",
       " ('solutions', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('its', 'PRON'),\n",
       " ('prison', 'NOUN'),\n",
       " ('cell', 'NOUN'),\n",
       " ('shortage', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('says', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('no', 'DET'),\n",
       " ('.', '.'),\n",
       " (\"''\", '.'),\n",
       " ('The', 'DET'),\n",
       " ('group', 'NOUN'),\n",
       " ('says', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('standardized', 'ADJ'),\n",
       " ('achievement', 'NOUN'),\n",
       " ('test', 'NOUN'),\n",
       " ('scores', 'NOUN'),\n",
       " ('are', 'VERB'),\n",
       " ('greatly', 'ADV'),\n",
       " ('inflated', 'ADP'),\n",
       " ('because', 'ADP'),\n",
       " ('teachers', 'NOUN'),\n",
       " ('often', 'ADV'),\n",
       " ('``', '.'),\n",
       " ('teach', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('test', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('as', 'ADP'),\n",
       " ('Mrs.', 'NOUN'),\n",
       " ('Yeargin', 'NOUN'),\n",
       " ('did', 'VERB'),\n",
       " ('*?*', 'X'),\n",
       " (',', '.'),\n",
       " ('although', 'ADP'),\n",
       " ('most', 'ADJ'),\n",
       " ('are', 'VERB'),\n",
       " ('never', 'ADV'),\n",
       " ('caught', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('.', '.'),\n",
       " ('Typical', 'ADP'),\n",
       " ('rates', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('secondary', 'ADJ'),\n",
       " ('market', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('8.60', 'ADP'),\n",
       " ('%', 'NOUN'),\n",
       " ('one', 'NUM'),\n",
       " ('month', 'NOUN'),\n",
       " (';', '.'),\n",
       " ('8.55', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('three', 'NUM'),\n",
       " ('months', 'NOUN'),\n",
       " (';', '.'),\n",
       " ('8.35', 'ADP'),\n",
       " ('%', 'NOUN'),\n",
       " ('six', 'NUM'),\n",
       " ('months', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('offer', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('which', 'DET'),\n",
       " ('*T*-2', 'X'),\n",
       " ('was', 'VERB'),\n",
       " ('due', 'ADJ'),\n",
       " ('*-3', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('expire', 'VERB'),\n",
       " ('yesterday', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('is', 'VERB'),\n",
       " ('conditional', 'ADJ'),\n",
       " ('on', 'ADP'),\n",
       " ('50.1', 'ADP'),\n",
       " ('%', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " (\"Dunkin'\", 'NOUN'),\n",
       " ('common', 'ADJ'),\n",
       " ('shares', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('on', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('fully', 'ADV'),\n",
       " ('diluted', 'VERB'),\n",
       " ('basis', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('being', 'VERB'),\n",
       " ('tendered', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('withdrawal', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('company', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('poison', 'NOUN'),\n",
       " ('pill', 'NOUN'),\n",
       " ('rights', 'NOUN'),\n",
       " ('plan', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Meanwhile', 'ADV'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('National', 'NOUN'),\n",
       " ('Association', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Purchasing', 'NOUN'),\n",
       " ('Management', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('its', 'PRON'),\n",
       " ('latest', 'ADJ'),\n",
       " ('survey', 'NOUN'),\n",
       " ('indicated', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('manufacturing', 'NOUN'),\n",
       " ('economy', 'NOUN'),\n",
       " ('contracted', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('October', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('sixth', 'ADJ'),\n",
       " ('consecutive', 'ADJ'),\n",
       " ('month', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('While', 'ADP'),\n",
       " ('Vichy', 'NOUN'),\n",
       " ('collaborated', 'ADP'),\n",
       " ('with', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('Germans', 'NOUN'),\n",
       " ('during', 'ADP'),\n",
       " ('World', 'NOUN'),\n",
       " ('War', 'NOUN'),\n",
       " ('II', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('deaths', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('thousands', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Resistance', 'ADP'),\n",
       " ('fighters', 'ADP'),\n",
       " ('and', 'CONJ'),\n",
       " ('Jews', 'ADP'),\n",
       " (',', '.'),\n",
       " ('its', 'PRON'),\n",
       " ('officials', 'NOUN'),\n",
       " ('needed', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('diversionary', 'ADP'),\n",
       " ('symbolic', 'ADP'),\n",
       " ('traitor', 'ADP'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('firm', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('NASD', 'NOUN'),\n",
       " ('differ', 'ADP'),\n",
       " ('over', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('meaning', 'VERB'),\n",
       " ('of', 'ADP'),\n",
       " ('markup', 'ADP'),\n",
       " ('and', 'CONJ'),\n",
       " ('markdown', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('he', 'PRON'),\n",
       " ('added', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('*T*-1', 'X'),\n",
       " ('.', '.'),\n",
       " ('When', 'ADV'),\n",
       " ('test', 'VERB'),\n",
       " ('booklets', 'NOUN'),\n",
       " ('were', 'VERB'),\n",
       " ('passed', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('out', 'PRT'),\n",
       " ('48', 'NUM'),\n",
       " ('hours', 'NOUN'),\n",
       " ('ahead', 'ADV'),\n",
       " ('of', 'ADP'),\n",
       " ('time', 'NOUN'),\n",
       " ('*T*-2', 'X'),\n",
       " (',', '.'),\n",
       " ('she', 'PRON'),\n",
       " ('says', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('she', 'PRON'),\n",
       " ('copied', 'ADP'),\n",
       " ('questions', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('social', 'ADJ'),\n",
       " ('studies', 'NOUN'),\n",
       " ('section', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('gave', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('answers', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('students', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('In', 'ADP'),\n",
       " ('1975', 'NUM'),\n",
       " (',', '.'),\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out=h_viterbi(test_words)\n",
    "test_out[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042816365366317"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking accuracy using base HMM & VITERBI algorithm\n",
    "\n",
    "chk_tags = [i for i, j in zip(test_out, test_tagd) if i == j] \n",
    "\n",
    "accuracy = len(chk_tags)/len(test_out)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Smoothing to deal with unknown words\n",
    "### So when an unknown word appear in the test data \n",
    "#### there are chances that the transition probability may be zero\n",
    "#### the emission probability will definitely be zero\n",
    "#### i.e. P(T2|T1) = 0 , if we did not have the sequence T1 -> T2 in the training data. As all P(T2|T1) are non zeros, we do not need to modify the transition probability.\n",
    "#### P(W|T) = 0 , as we do not have the word in out training data\n",
    "#### here T - tag of unknow word W \n",
    "\n",
    "#### Emission Probability\n",
    "\n",
    "#### P(W|T) = ((# W as T)+K ) / (#T + K* #words )\n",
    "\n",
    "#### WHERE,\n",
    "#### #words - total number of words vailable in the vocabulary\n",
    "#### K - a value bw=etween 0-1 acts as a weight given to unknown values\n",
    "#### (# W as T) - nuber of time W is tagged as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified Emission Probability\n",
    "\n",
    "def w_g_t_md( word,tag,k=1,train_d=train_tagd):\n",
    "    T=list(set([i[1] for i in train_d]))\n",
    "    wtr=list(set([i[0] for i in train_d]))\n",
    "    onlyt=[wt for wt in train_d if wt[1]==tag ]\n",
    "    w=[w for w in onlyt if w[0]==word]\n",
    "    \n",
    "    emission = (len(w)+k)/(len(onlyt)+k*len(wtr))\n",
    "    return emission\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED HMM-VITERBI ALGORITHM ( BASE FORM) according to Laplace smoothing\n",
    "\n",
    "def h_viterbi_lp(words,train_bag =train_tagd):\n",
    "    pos=[]\n",
    "    T=list(set([i[1] for i in train_bag]))\n",
    "    \n",
    "    for index, word in enumerate(words):\n",
    "        state_p=[]\n",
    "        for tag in T:\n",
    "            if index ==0:\n",
    "                transition_p=tags_df.loc['.',tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[pos[-1],tag]\n",
    "                \n",
    "            #emission probability\n",
    "            emission_p = w_g_t_md(words[index],tag)\n",
    "            state=transition_p * emission_p\n",
    "            state_p.append(state)\n",
    "            \n",
    "        max_p=max(state_p) #evaluating maximum likelyhood\n",
    "        \n",
    "        w_pos=T[state_p.index(max_p)]\n",
    "        pos.append(w_pos)\n",
    "    \n",
    "    return list(zip(words,pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking accuracy\n",
    "test_lp = h_viterbi_lp(test_words)\n",
    "chk_tags = [i for i, j in zip(test_lp, test_tagd) if i == j] \n",
    "\n",
    "accuracy_lp = len(chk_tags)/len(test_lp)\n",
    "accuracy_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrect tag cases for base \n",
    "incorrect_tagged_cases = [[test_tagd[i-1],j,test_tagd[i+1]] for i, j in enumerate(zip(test_out, test_tagd)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrect tag cases for lp\n",
    "incorrect_tagged_cases_lp = [[test_tagd[i-1],j,test_tagd[i+1]] for i, j in enumerate(zip(test_lp, test_tagd)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking accuracy\n",
    "print('accuracy of vanila viterbi form = ',accuracy)\n",
    "print('accuracy of viterbi + laplace smoothing form = ',accuracy_lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi + ruled base tagging to deal with unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining regexp for ruled base tagging\n",
    "\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              \n",
    "    (r'.*ed$', 'VERB'),               \n",
    "    (r'.*es$', 'VERB'),               \n",
    "    (r'.*ould$', 'VERB'),              \n",
    "    (r'.*\\'s$', 'NOUN'),              \n",
    "    (r'.*s$', 'NOUN'),                \n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),\n",
    "    (r'.*able$', 'ADJ'),\n",
    "    (r'.*ly$', 'ADV'),\n",
    "    (r'.*', 'NOUN')\n",
    "      \n",
    "]\n",
    "\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regexp_tagger.tag(['Editorials'])[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi + Rule based tagger \n",
    "\n",
    "def h_viterbi_rb(words,train_bag=train_tagd):\n",
    "    pos=[]\n",
    "    T=list(set([i[1] for i in train_bag]))\n",
    "    wtr=list(set([i[0] for i in train_bag]))\n",
    "    \n",
    "    for index, word in enumerate(words):\n",
    "\n",
    "        if word in wtr:\n",
    "            state_p=[]\n",
    "            for tag in T:\n",
    "                if index ==0:\n",
    "                    transition_p=tags_df.loc['.',tag]\n",
    "                else:\n",
    "                    transition_p = tags_df.loc[pos[-1],tag]\n",
    "\n",
    "                #emission probability\n",
    "                emission_p = w_g_t(words[index],tag)\n",
    "                state=transition_p * emission_p\n",
    "                state_p.append(state)\n",
    "\n",
    "            max_p=max(state_p) #evaluating maximum likelyhood\n",
    "\n",
    "            w_pos=T[state_p.index(max_p)]\n",
    "            pos.append(w_pos)\n",
    "        else:\n",
    "            wordx=[]\n",
    "            wordx.append(word)\n",
    "            w_pos=regexp_tagger.tag(wordx)\n",
    "            pos.append(w_pos[0][1])\n",
    "            \n",
    "    \n",
    "    return list(zip(words,pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking accuracy\n",
    "\n",
    "test_rb = h_viterbi_rb(test_words)\n",
    "chk_tags = [i for i, j in zip(test_rb, test_tagd) if i == j] \n",
    "\n",
    "accuracy_rb = len(chk_tags)/len(test_rb)\n",
    "accuracy_rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrect tag cases for rb\n",
    "incorrect_tagged_cases_rb = [[test_tagd[i-1],j,test_tagd[i+1]] for i, j in enumerate(zip(test_rb, test_tagd)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy comparison\n",
    "\n",
    "print('accuracy of vanila viterbi form = ',accuracy)\n",
    "print('accuracy of viterbi + laplace smoothing form = ',accuracy_lp)\n",
    "print('accuracy of viterbi + rule based form = ',accuracy_rb)\n",
    "\n",
    "#Viterbi + rule based form has high tagging accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking with test samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking with test samples\n",
    "\n",
    "text=open('Test_sentences.txt').read()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tokens\n",
    "token_txt=word_tokenize(text)\n",
    "token_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging by vanila viterbi algorithm\n",
    "\n",
    "st=h_viterbi(token_txt)\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgging by modified viterbi algorithm (laplace smoothing)\n",
    "lp=h_viterbi_lp(token_txt)\n",
    "lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tagging by viterbi + rule base tagger\n",
    "\n",
    "rb=h_viterbi_rb(token_txt)\n",
    "rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison\n",
    "\n",
    "#EXTRACTING POS TAGS\n",
    "st_tags=[i[1] for i in st]\n",
    "lp_tags=[i[1] for i in lp]\n",
    "rb_tags=[i[1] for i in rb]\n",
    "\n",
    "\n",
    "# Many words(such as Android, Google,NASA,Satellite, etc.) which were tagged wrongly by vanila viterbi are corrected by viterbi + rule based tagger\n",
    "\n",
    "compare=pd.DataFrame({'Words':token_txt,'vanila viterbi':st_tags,'Laplace viterbi':lp_tags,'rule based viterbi':rb_tags})\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
